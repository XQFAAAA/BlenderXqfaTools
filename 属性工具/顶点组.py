# type: ignore
import bpy
import numpy as np
import time
from typing import Dict, Tuple, Set, List, Optional

class DATA_PT_vertex_group_tools(bpy.types.Panel):
    bl_label = "é¡¶ç‚¹ç»„"
    bl_space_type = 'VIEW_3D'
    bl_region_type = 'UI'
    bl_category = 'XBone'

    @classmethod
    def poll(cls, context):
        # åªæœ‰å½“ä¸»é¢æ¿æ¿€æ´»äº†æ­¤å­é¢æ¿æ—¶æ‰æ˜¾ç¤º
        return getattr(context.scene, 'active_xbone_subpanel', '') == 'AttributeTools'

    def draw(self, context):
        layout = self.layout

        obj = context.object
        # æ·»åŠ å®‰å…¨æ£€æŸ¥ï¼Œç¡®ä¿ç‰©ä½“å­˜åœ¨ä¸”æ˜¯ç½‘æ ¼ç‰©ä½“
        if obj is None or obj.type != 'MESH':
            layout.label(text="è¯·é€‰æ‹©ä¸€ä¸ªç½‘æ ¼ç‰©ä½“")
            return
        count0 = len(obj.vertex_groups)
        
        # è·å–å­˜å‚¨çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºé»˜è®¤å€¼
        stats = obj.get("vertex_group_stats", {
            "total": count0,
            "with_weight": "N/A",
            "zero_weight": "N/A"
        })
        
        col = layout.column(align=True)
        row = col.row(align=True)
        row.label(text=f"æ•°é‡: {stats['total']}")
        row.label(text=f"æœ‰æƒé‡: {stats['with_weight']}")
        row.label(text=f"æ— æƒé‡: {stats['zero_weight']}")

        row = col.row(align=True)
        row.operator(O_VertexGroupsCount.bl_idname, text=O_VertexGroupsCount.bl_label, icon="GROUP_VERTEX")
        row.operator(O_VertexGroupsDelNoneActive.bl_idname, text=O_VertexGroupsDelNoneActive.bl_label, icon="GROUP_VERTEX")

        row = col.row(align=True)
        row.prop(context.scene, "similarity_threshold")
        row.operator(O_VertexGroupsMatchRename.bl_idname, text=O_VertexGroupsMatchRename.bl_label, icon="SORTBYEXT")
        row.separator()  # æ·»åŠ åˆ†å‰²çº¿
        row.operator(O_VertexGroupsSortMatch.bl_idname, text=O_VertexGroupsSortMatch.bl_label, icon="SORTSIZE")


class O_VertexGroupsCount(bpy.types.Operator):
    bl_idname = "xbone.vertex_groups_count"
    bl_label = "ç»Ÿè®¡æœ‰æ— æƒé‡æ•°é‡"
    bl_description = "ç»Ÿè®¡æ´»åŠ¨ç‰©ä½“é¡¶ç‚¹ç»„ä¸­æœ‰æƒé‡å’Œæ— æƒé‡çš„æ•°é‡"
    
    def execute(self, context):
        obj = context.active_object
        if obj and obj.type == 'MESH':
            vertex_groups = obj.vertex_groups
            mesh = obj.data
            
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•æ£€æŸ¥é¡¶ç‚¹ç»„æ˜¯å¦æœ‰æƒé‡
            count_with_weight = 0
            count_zero_weight = 0
            
            # ä¸ºæ¯ä¸ªé¡¶ç‚¹ç»„åˆ›å»ºä¸€ä¸ªæ ‡è®°ï¼Œåˆå§‹ä¸ºFalse(æ— æƒé‡)
            has_weights = [False] * len(vertex_groups)
            
            # éå†æ‰€æœ‰é¡¶ç‚¹
            for vertex in mesh.vertices:
                for group in vertex.groups:
                    group_index = group.group
                    # å¦‚æœæ‰¾åˆ°è‡³å°‘ä¸€ä¸ªé¡¶ç‚¹æœ‰è¯¥ç»„çš„æƒé‡ï¼Œæ ‡è®°ä¸ºTrue
                    if group.weight > 0:
                        has_weights[group_index] = True
            
            # ç»Ÿè®¡ç»“æœ
            for has_weight in has_weights:
                if has_weight:
                    count_with_weight += 1
            count_zero_weight = len(vertex_groups) - count_with_weight
            
            # å°†ç»“æœå­˜å‚¨åœ¨å¯¹è±¡å±æ€§ä¸­
            obj["vertex_group_stats"] = {
                "total": len(vertex_groups),
                "with_weight": count_with_weight,
                "zero_weight": count_zero_weight
            }
            
            self.report({'INFO'}, f"ç»Ÿè®¡å®Œæˆ: æ€»æ•° {len(vertex_groups)}, æœ‰æƒé‡ {count_with_weight}, æ— æƒé‡ {count_zero_weight}")
        else:
            self.report({'ERROR'}, "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªMeshå¯¹è±¡ä½œä¸ºæ´»åŠ¨å¯¹è±¡ã€‚")
            return {'CANCELLED'}

        return {'FINISHED'}


class O_VertexGroupsDelNoneActive(bpy.types.Operator):
    bl_idname = "xbone.vertex_groups_del_none_active"
    bl_label = "åˆ é™¤æ— æƒé‡é¡¶ç‚¹ç»„"
    bl_description = "åˆ é™¤æ´»åŠ¨ç‰©ä½“ä¸­æ²¡æœ‰é¡¶ç‚¹æƒé‡çš„é¡¶ç‚¹ç»„"
    
    def execute(self, context):
        obj = context.active_object
        if obj and obj.type == 'MESH':
            vertex_groups = obj.vertex_groups
            mesh = obj.data
            
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•æ£€æŸ¥é¡¶ç‚¹ç»„æ˜¯å¦æœ‰æƒé‡
            has_weights = [False] * len(vertex_groups)
            
            # éå†æ‰€æœ‰é¡¶ç‚¹
            for vertex in mesh.vertices:
                for group in vertex.groups:
                    group_index = group.group
                    if group.weight > 0:
                        has_weights[group_index] = True
            
            # æ”¶é›†è¦åˆ é™¤çš„é¡¶ç‚¹ç»„åç§°ï¼ˆé€†åºä»¥ä¾¿å®‰å…¨åˆ é™¤ï¼‰
            groups_to_remove = []
            for i, has_weight in reversed(list(enumerate(has_weights))):
                if not has_weight:
                    groups_to_remove.append(vertex_groups[i].name)
            
            # åˆ é™¤æ— æƒé‡é¡¶ç‚¹ç»„
            for group_name in groups_to_remove:
                vertex_groups.remove(vertex_groups[group_name])
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if "vertex_group_stats" in obj:
                remaining_count = len(vertex_groups)
                obj["vertex_group_stats"] = {
                    "total": remaining_count,
                    "with_weight": remaining_count,  # åˆ é™¤åå‰©ä¸‹çš„éƒ½æ˜¯æœ‰æƒé‡çš„
                    "zero_weight": 0
                }
            
            self.report({'INFO'}, f"å·²åˆ é™¤ {len(groups_to_remove)} ä¸ªæ— æƒé‡é¡¶ç‚¹ç»„ï¼š{groups_to_remove}")
        else:
            self.report({'ERROR'}, "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªMeshå¯¹è±¡ä½œä¸ºæ´»åŠ¨å¯¹è±¡ã€‚")
            return {'CANCELLED'}

        return {'FINISHED'}

# ----------------------------------------------------------------
# 3. åŒ¹é…é‡å‘½åæ“ä½œ (Match Rename Operator) - ğŸ’¥ ä¼˜åŒ–
# ----------------------------------------------------------------
class O_VertexGroupsMatchRename(bpy.types.Operator):
    bl_idname = "xbone.vertex_groups_match_rename"
    bl_label = "åŒ¹é…é‡å‘½å"
    bl_description = ("åŸºäºé¡¶ç‚¹å¹³å‡ä½ç½®åŒ¹é…é‡å‘½åæ´»åŠ¨ç‰©ä½“çš„é¡¶ç‚¹ç»„ï¼ˆéœ€é€‰æ‹©2ä¸ªç½‘æ ¼ç‰©ä½“ï¼‰\n"
                     "æˆ‘ç”¨æ¥ç»™é¸£æ½®æå–çš„æ¨¡å‹æŒ‰è§£åŒ…çš„æ¨¡å‹éª¨éª¼é‡å‘½åï¼Œè¿™æ ·é¡¶ç‚¹ç»„æœ‰åç§°æ„ä¹‰ä¹Ÿå¯ä»¥æ“æ§")
    
    def execute(self, context: bpy.types.Context) -> Set[str]:
        self.similarity_threshold = context.scene.similarity_threshold
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        
        try:
            # éªŒè¯è¾“å…¥å¹¶è·å–ç›®æ ‡ç‰©ä½“
            obj_a, obj_b = self._validate_input(context)
            
            # æ‰§è¡ŒåŒ¹é…é‡å‘½åå¹¶è·å–è¯¦ç»†ç»“æœ
            # ä¼˜åŒ–: åªéœ€è¦è®¡ç®—ä¸€æ¬¡ä¸­å¿ƒç‚¹
            centers_a = self._get_vertex_group_centers(obj_a)
            centers_b = self._get_vertex_group_centers(obj_b)

            if not centers_a:
                raise Exception(f"æºç‰©ä½“ ({obj_a.name}) æ²¡æœ‰éç©ºé¡¶ç‚¹ç»„")
            if not centers_b:
                raise Exception(f"ç›®æ ‡ç‰©ä½“ ({obj_b.name}) æ²¡æœ‰éç©ºé¡¶ç‚¹ç»„")

            result = self._rename_matching_vertex_groups(obj_a, obj_b, centers_a, centers_b)
            
            # æ‰“å°è¯¦ç»†ç»“æœåˆ°æ§åˆ¶å°
            self._print_detailed_results(obj_a, obj_b, result)
            
            # è®¡ç®—æ€»è€—æ—¶
            elapsed_time = time.time() - start_time
            time_msg = f"æ€»è€—æ—¶: {elapsed_time:.4f}ç§’" # å¢åŠ ç²¾åº¦
            
            # æ ¹æ®ç»“æœè¿”å›é€‚å½“çš„æ¶ˆæ¯
            if result['renamed_count'] > 0:
                self.report({'INFO'}, f"æˆåŠŸåŒ¹é…é‡å‘½å {result['renamed_count']} ä¸ªé¡¶ç‚¹ç»„ ({time_msg})")
            else:
                self.report({'WARNING'}, f"æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„é¡¶ç‚¹ç»„ ({time_msg})")
                
            return {'FINISHED'}
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.report({'ERROR'}, f"{str(e)} (è€—æ—¶: {elapsed_time:.4f}ç§’)")
            return {'CANCELLED'}
    
    def _validate_input(self, context: bpy.types.Context) -> Tuple[bpy.types.Object, bpy.types.Object]:
        """éªŒè¯è¾“å…¥å¹¶è¿”å›ä¸¤ä¸ªç½‘æ ¼ç‰©ä½“"""
        selected_objs = context.selected_objects
        active_obj = context.active_object
        
        # éªŒè¯é€‰æ‹©æ•°é‡
        if len(selected_objs) != 2:
            raise ValueError("è¯·é€‰æ‹©2ä¸ªç½‘æ ¼ç‰©ä½“")
            
        # éªŒè¯æ´»åŠ¨ç‰©ä½“
        if active_obj not in selected_objs:
            raise ValueError("æ´»åŠ¨ç‰©ä½“å¿…é¡»æ˜¯é€‰ä¸­çš„ç‰©ä½“ä¹‹ä¸€")
            
        # è·å–ä¸¤ä¸ªç‰©ä½“
        # Aç‰©ä½“: æºï¼ˆæä¾›åç§°çš„ï¼‰
        # Bç‰©ä½“: ç›®æ ‡ï¼ˆè¢«é‡å‘½åçš„ï¼Œæ´»åŠ¨ç‰©ä½“ï¼‰
        obj_b = active_obj
        obj_a = next(obj for obj in selected_objs if obj != active_obj)
        
        # éªŒè¯ç‰©ä½“ç±»å‹
        if obj_a.type != 'MESH' or obj_b.type != 'MESH':
            raise ValueError("ä¸¤ä¸ªç‰©ä½“éƒ½å¿…é¡»æ˜¯ç½‘æ ¼ç±»å‹")
            
        # éªŒè¯æ¨¡å¼ (é‡è¦ï¼šéœ€è¦å¯¹è±¡æ¨¡å¼æ‰èƒ½è·å–æ­£ç¡®çš„çŸ©é˜µå’Œæ•°æ®)
        if context.mode != 'OBJECT':
             raise ValueError("è¯·åˆ‡æ¢åˆ°å¯¹è±¡æ¨¡å¼ (Object Mode) ä»¥ç¡®ä¿è®¡ç®—å‡†ç¡®æ€§")
            
        return obj_a, obj_b
    
    def _get_vertex_group_centers(self, obj: bpy.types.Object) -> Dict[str, np.ndarray]:
        """
        ä¼˜åŒ–ï¼šå‘é‡åŒ–è·å–æ¯ä¸ªé¡¶ç‚¹ç»„çš„ä¸­å¿ƒä½ç½®ï¼ˆå¹³å‡ä½ç½®ï¼‰ã€‚
        1. è·å–æ‰€æœ‰é¡¶ç‚¹çš„å…¨å±€åæ ‡ (co * matrix_world)
        2. è·å–æ‰€æœ‰é¡¶ç‚¹çš„æ‰€æœ‰é¡¶ç‚¹ç»„æƒé‡ï¼ˆBlender API ç›¸å¯¹é«˜æ•ˆçš„æ–¹å¼ï¼‰
        3. åˆ©ç”¨ NumPy å¹¿æ’­å’Œæ±‚å’Œè®¡ç®—åŠ æƒå¹³å‡ä¸­å¿ƒç‚¹ã€‚
        """
        centers: Dict[str, np.ndarray] = {}
        mesh = obj.data
        
        if not obj.vertex_groups:
            return centers

        # 1. è·å–æ‰€æœ‰é¡¶ç‚¹çš„å…¨å±€åæ ‡
        num_verts = len(mesh.vertices)
        verts_co = np.zeros((num_verts, 3))
        mesh.vertices.foreach_get('co', verts_co.ravel())
        
        matrix = np.array(obj.matrix_world)
        # å°†å±€éƒ¨åæ ‡è½¬æ¢ä¸ºå…¨å±€åæ ‡ï¼šV_global = V_local @ R.T + T
        global_verts = verts_co @ matrix[:3, :3].T + matrix[:3, 3]

        # 2. è·å–æ‰€æœ‰é¡¶ç‚¹ç»„çš„åç§°å’Œç´¢å¼•æ˜ å°„
        vg_names = [vg.name for vg in obj.vertex_groups]
        vg_map = {name: i for i, name in enumerate(vg_names)}
        
        # 3. è·å–æ‰€æœ‰é¡¶ç‚¹ç»„çš„æƒé‡ã€‚
        # ä½¿ç”¨ bmesh æˆ– foreach_get æ— æ³•ç›´æ¥é«˜æ•ˆè·å–æ‰€æœ‰é¡¶ç‚¹çš„æ‰€æœ‰æƒé‡ã€‚
        # ä»éœ€éå†é¡¶ç‚¹ï¼Œä½†å¯ä»¥æ‰¹é‡å¤„ç†ï¼ŒåŸå§‹æ–¹æ³•å·²æ˜¯å¸¸è§é«˜æ•ˆåšæ³•ã€‚
        # ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥ä» Blender çš„æƒé‡ API è·å–å¹¶è½¬æ¢ä¸º NumPy çŸ©é˜µã€‚
        
        # åˆ›å»ºä¸€ä¸ª Num_Verts x Num_Groups çš„ç¨€ç–çŸ©é˜µæ¥å­˜å‚¨æƒé‡ (å¦‚æœå¤§éƒ¨åˆ†æƒé‡ä¸º0)
        # ä½†ä¸ºäº†ç®€å•å’Œé€šç”¨æ€§ï¼Œæˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªç¨ å¯†åˆ—è¡¨/å­—å…¸æ¥å¤„ç†éé›¶æƒé‡
        
        # å­˜å‚¨æ¯ä¸ªé¡¶ç‚¹ç»„çš„ (æ€»åŠ æƒä½ç½®, æ€»æƒé‡)
        vg_data: Dict[str, Tuple[np.ndarray, float]] = {name: (np.zeros(3), 0.0) for name in vg_names}
        
        # éå†æ‰€æœ‰é¡¶ç‚¹åŠå…¶æƒé‡ï¼Œè®¡ç®—åŠ æƒå’Œ
        for i, vertex in enumerate(mesh.vertices):
            co = global_verts[i]
            for group in vertex.groups:
                group_index = group.group
                weight = group.weight
                
                if weight > 0:
                    group_name = obj.vertex_groups[group_index].name
                    
                    # ä½¿ç”¨ NumPy æ•°ç»„è¿›è¡ŒåŠ æ³•
                    current_sum, current_weight = vg_data[group_name]
                    vg_data[group_name] = (current_sum + co * weight, current_weight + weight)

        # 4. è®¡ç®—å¹³å‡ä¸­å¿ƒç‚¹
        for name, (weighted_sum, total_weight) in vg_data.items():
            if total_weight > 0:
                # å¹³å‡ä½ç½® = æ€»åŠ æƒä½ç½® / æ€»æƒé‡
                centers[name] = weighted_sum / total_weight
                
        return centers

    def _calculate_similarity_vectorized(self, centers_a: Dict[str, np.ndarray], centers_b: Dict[str, np.ndarray], threshold: float) -> Tuple[List[Tuple[str, Optional[str], str]], int, int]:
        """
        ä¼˜åŒ–: å‘é‡åŒ–è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µå¹¶å¯»æ‰¾æœ€ä½³åŒ¹é…ã€‚
        A: æº (åç§°æ¥æº)
        B: ç›®æ ‡ (è¢«é‡å‘½å)
        """
        # 1. å‡†å¤‡æ•°æ®ï¼šè½¬æ¢ä¸º NumPy æ•°ç»„
        a_names = list(centers_a.keys())
        b_names = list(centers_b.keys())
        a_centers = np.array(list(centers_a.values())) # N_a x 3
        b_centers = np.array(list(centers_b.values())) # N_b x 3
        
        if a_centers.size == 0 or b_centers.size == 0:
             return [], 0, 0
        
        # 2. å‘é‡åŒ–è®¡ç®—æ‰€æœ‰è·ç¦» (æ¬§å‡ é‡Œå¾—è·ç¦»)
        # ä½¿ç”¨ NumPy å¹¿æ’­è®¡ç®—è·ç¦»ï¼šDistance Matrix M (N_b x N_a)
        # M[i, j] = ||b_centers[i] - a_centers[j]||
        
        # b_centers (N_b x 3)
        # a_centers (N_a x 3)
        
        # (b_i - a_j)^2 = b_i^2 - 2*b_i*a_j + a_j^2
        b_sq = np.sum(b_centers**2, axis=1, keepdims=True)  # N_b x 1
        a_sq = np.sum(a_centers**2, axis=1, keepdims=True).T # 1 x N_a
        
        # 2 * b_i * a_j
        b_dot_a = b_centers @ a_centers.T # N_b x N_a
        
        # è·ç¦»çš„å¹³æ–¹
        dist_sq = b_sq - 2 * b_dot_a + a_sq
        # é¿å…æµ®ç‚¹è¯¯å·®å¯¼è‡´çš„å¾®å°è´Ÿæ•°
        dist_sq = np.maximum(dist_sq, 0)
        distances = np.sqrt(dist_sq) # N_b x N_a
        
        # 3. å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (ç›¸ä¼¼åº¦ = 1 / (1 + è·ç¦»))
        similarity_matrix = 1.0 / (1.0 + distances) # N_b x N_a
        
        # 4. å¯»æ‰¾æœ€ä½³åŒ¹é…ï¼ˆè´ªå©ªåŒ¹é…ï¼‰
        renamed_count = 0
        matched_a_indices: Set[int] = set() # å·²åŒ¹é…çš„ A ç»„çš„ç´¢å¼•
        matches: List[Tuple[str, Optional[str], str]] = []

        # éå† B ç»„ (ç›®æ ‡ç»„)
        for i, b_name in enumerate(b_names):
            best_match_index = -1
            best_similarity = 0.0
            
            # è·å– B ç»„ i ä¸æ‰€æœ‰ A ç»„çš„ç›¸ä¼¼åº¦è¡Œå‘é‡
            sim_row = similarity_matrix[i, :]

            # å¯»æ‰¾æ»¡è¶³é˜ˆå€¼çš„æœ€ä½³åŒ¹é… A ç»„
            for j, a_name in enumerate(a_names):
                if j in matched_a_indices:
                    continue # è·³è¿‡å·²åŒ¹é…çš„ A ç»„
                    
                similarity = sim_row[j]
                
                if similarity > best_similarity and similarity >= threshold:
                    best_similarity = similarity
                    best_match_index = j
            
            # è®°å½•ç»“æœ
            if best_match_index != -1:
                a_name = a_names[best_match_index]
                matched_a_indices.add(best_match_index) # æ ‡è®° A ç»„å·²ä½¿ç”¨
                renamed_count += 1
                matches.append((b_name, a_name, f"{best_similarity:.3f}"))
            else:
                matches.append((b_name, None, "no match"))
        
        return matches, len(a_names), len(b_names)

    def _rename_matching_vertex_groups(self, 
                                     obj_a: bpy.types.Object, 
                                     obj_b: bpy.types.Object,
                                     centers_a: Dict[str, np.ndarray],
                                     centers_b: Dict[str, np.ndarray]) -> Dict[str, any]:
        """åŒ¹é…å¹¶é‡å‘½åé¡¶ç‚¹ç»„ (ä½¿ç”¨å‘é‡åŒ–åŒ¹é…)"""
        
        matches, total_a, total_b = self._calculate_similarity_vectorized(
            centers_a, 
            centers_b, 
            self.similarity_threshold
        )
        
        renamed_count = 0
        
        # æ‰§è¡Œé‡å‘½å
        for b_name, a_name, similarity_str in matches:
            if a_name:
                obj_b.vertex_groups[b_name].name = a_name
                renamed_count += 1
        
        return {
            'renamed_count': renamed_count,
            'matches': matches,
            'total_a': total_a,
            'total_b': total_b
        }
    
    def _print_detailed_results(self, 
                              obj_a: bpy.types.Object, 
                              obj_b: bpy.types.Object, 
                              result: Dict[str, any]) -> None:
        """æ‰“å°è¯¦ç»†ç»“æœåˆ°æ§åˆ¶å°"""
        header = f"é¡¶ç‚¹ç»„åŒ¹é…ä¸é‡å‘½åè¯¦ç»†ç»“æœ (æºA: {obj_a.name}, ç›®æ ‡B: {obj_b.name})"
        separator = "=" * len(header)
        
        print(f"\n{separator}")
        print(header)
        print(separator)
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold:.3f}")
        print(f"{'Bç‰©ä½“åŸå§‹åç§°':<30} {'é‡å‘½åä¸º':<30} {'ç›¸ä¼¼åº¦':<20}")
        print("-" * 80)
        
        matched = 0 
        unmatched = 0
        
        for b_name, a_name, similarity in result['matches']:

            if a_name:
                matched += 1
                print(f"{b_name:<30} â†’ {a_name:<30} {similarity:<20}")
            else:
                unmatched += 1
                print(f"{b_name:<30} â†’ {'ä¿ç•™åŸåç§°':<30} {'(æœªåŒ¹é…)':<20}")

        
        print(separator)
        print("æ€»ç»“:")
        print(f"  æºAç‰©ä½“éç©ºé¡¶ç‚¹ç»„æ•°é‡: {result['total_a']}")
        print(f"  ç›®æ ‡Bç‰©ä½“éç©ºé¡¶ç‚¹ç»„æ•°é‡: {result['total_b']}")
        print(f"  åŒ¹é…æ•°é‡: {matched}")
        print(f"  æœªåŒ¹é…æ•°é‡: {unmatched}")
        print(f"  æ€»é‡å‘½åæ•°é‡: {result['renamed_count']}")
        print(separator)


# ----------------------------------------------------------------
# 4. åç§°æ’åºæ“ä½œ (Sort Match Operator) - ğŸ’¥ ä¼˜åŒ–å¹¶å¢åŠ åé¦ˆ
# ----------------------------------------------------------------
class O_VertexGroupsSortMatch(bpy.types.Operator):
    bl_idname = "xbone.vertex_groups_sort_match"
    bl_label = "åç§°æ’åº (é«˜æ•ˆ)"
    bl_description = ("ä¸¥æ ¼æŒ‰ç…§é€‰æ‹©ç‰©ä½“çš„é¡¶ç‚¹ç»„é¡ºåºé‡æ–°æ’åˆ—æ´»åŠ¨ç‰©ä½“çš„é¡¶ç‚¹ç»„\n"
                     "ä½¿ç”¨é«˜æ•ˆç®—æ³•ï¼šä¿å­˜æƒé‡ -> æ¸…ç©º -> æŒ‰é¡ºåºé‡å»º/æ¢å¤æƒé‡")

    def execute(self, context):
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        
        try:
            selected_objs = context.selected_objects
            active_obj = context.active_object
            
            # éªŒè¯é€‰æ‹©
            if len(selected_objs) != 2:
                raise ValueError("è¯·é€‰æ‹©2ä¸ªç½‘æ ¼ç‰©ä½“")
                
            if active_obj not in selected_objs:
                raise ValueError("æ´»åŠ¨ç‰©ä½“å¿…é¡»æ˜¯é€‰ä¸­çš„ç‰©ä½“ä¹‹ä¸€")
                
            source_obj = next(obj for obj in selected_objs if obj != active_obj)
            target_obj = active_obj

            if source_obj.type != 'MESH' or target_obj.type != 'MESH':
                raise ValueError("ä¸¤ä¸ªç‰©ä½“éƒ½å¿…é¡»æ˜¯ç½‘æ ¼ç±»å‹")
            
            # ç¡®ä¿å¤„äºå¯¹è±¡æ¨¡å¼ä»¥æ“ä½œé¡¶ç‚¹ç»„
            if context.mode != 'OBJECT':
                 raise ValueError("è¯·åˆ‡æ¢åˆ°å¯¹è±¡æ¨¡å¼ (Object Mode)")
            
            # æ‰§è¡Œæ’åº
            result = self._sort_vertex_groups_optimized(target_obj, source_obj)
            
            # æ‰“å°è¯¦ç»†ç»“æœåˆ°æ§åˆ¶å°
            self._print_detailed_results(source_obj, target_obj, result)
            
            # è®¡ç®—æ€»è€—æ—¶
            elapsed_time = time.time() - start_time
            time_msg = f"æ€»è€—æ—¶: {elapsed_time:.4f}ç§’"
            
            self.report({'INFO'}, 
                       f"æ’åºå®Œæˆ: åŒ¹é… {result['matched']}ä¸ª, æ–°å»º {result['added']}ä¸ª ({time_msg})")
            
            return {'FINISHED'}
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.report({'ERROR'}, f"{str(e)} (è€—æ—¶: {elapsed_time:.4f}ç§’)")
            return {'CANCELLED'}
    
    def _sort_vertex_groups_optimized(self, target_obj: bpy.types.Object, source_obj: bpy.types.Object) -> Dict[str, any]:
        """
        ä¼˜åŒ–åçš„é¡¶ç‚¹ç»„æ’åºç®—æ³•ã€‚
        1. å¤‡ä»½ç›®æ ‡ç‰©ä½“çš„æ‰€æœ‰æƒé‡æ•°æ®ã€‚
        2. æ¸…ç©ºç›®æ ‡ç‰©ä½“çš„æ‰€æœ‰é¡¶ç‚¹ç»„ã€‚
        3. æŒ‰ç…§æºç‰©ä½“çš„é¡ºåºï¼Œé‡å»ºé¡¶ç‚¹ç»„å¹¶æ¢å¤æƒé‡ã€‚
        """
        
        target_vgs = target_obj.vertex_groups
        source_vgs = source_obj.vertex_groups
        
        # 1. å¤‡ä»½ç›®æ ‡ç‰©ä½“çš„æƒé‡æ•°æ®
        weight_data: Dict[str, Dict[int, float]] = {}
        original_vg_names = [vg.name for vg in target_vgs]
        
        mesh = target_obj.data
        
        # éå†æ‰€æœ‰é¡¶ç‚¹ï¼Œæ”¶é›†å®ƒä»¬çš„æƒé‡
        for vert in mesh.vertices:
            for group in vert.groups:
                vg_name = original_vg_names[group.group]
                if group.weight > 0:
                    if vg_name not in weight_data:
                        weight_data[vg_name] = {}
                    # å­˜å‚¨ (é¡¶ç‚¹ç´¢å¼•: æƒé‡)
                    weight_data[vg_name][vert.index] = group.weight

        # 2. æ¸…ç©ºç›®æ ‡ç‰©ä½“çš„æ‰€æœ‰é¡¶ç‚¹ç»„
        for i in range(len(target_vgs) - 1, -1, -1):
            target_vgs.remove(target_vgs[i])
            
        final_list: List[Tuple[str, str]] = [] # (æœ€ç»ˆåç§°, çŠ¶æ€)
        matched_count = 0
        added_count = 0
        
        # 3. æŒ‰ç…§æºç‰©ä½“çš„é¡ºåºï¼Œé‡å»ºé¡¶ç‚¹ç»„
        for desired_index, src_vg in enumerate(source_vgs):
            new_vg = target_vgs.new(name=src_vg.name)
            
            # æ¢å¤æƒé‡ï¼ˆå¦‚æœå¤‡ä»½æ•°æ®ä¸­å­˜åœ¨ï¼‰
            if src_vg.name in weight_data:
                vg_weights = weight_data.pop(src_vg.name)
                
                # æ‰¹é‡è®¾ç½®æƒé‡
                for vert_index, weight in vg_weights.items():
                    new_vg.add([vert_index], weight, 'REPLACE')
                
                matched_count += 1
                final_list.append((src_vg.name, 'å·²åŒ¹é…/ç§»åŠ¨'))
            else:
                added_count += 1
                final_list.append((src_vg.name, 'æ–°å»ºç©ºç»„'))
                
        # 4. å¤„ç†å¤šä½™çš„é¡¶ç‚¹ç»„
        extra_count = 0
        for extra_name, vg_weights in weight_data.items():
            new_vg = target_vgs.new(name=extra_name)
            
            # æ¢å¤æƒé‡
            for vert_index, weight in vg_weights.items():
                new_vg.add([vert_index], weight, 'REPLACE')
            
            extra_count += 1
            final_list.append((extra_name, 'å¤šä½™/ä¿ç•™'))
            
        return {
            'matched': matched_count,
            'added': added_count,
            'extra': extra_count,
            'original_total': len(original_vg_names),
            'source_total': len(source_vgs),
            'final_list': final_list
        }

    def _print_detailed_results(self, 
                              source_obj: bpy.types.Object, 
                              target_obj: bpy.types.Object, 
                              result: Dict[str, any]) -> None:
        """æ‰“å°è¯¦ç»†ç»“æœåˆ°æ§åˆ¶å°"""
        header = f"é¡¶ç‚¹ç»„æ’åºè¯¦ç»†ç»“æœ (æºA: {source_obj.name}, ç›®æ ‡B: {target_obj.name})"
        separator = "=" * len(header)
        
        print(f"\n{separator}")
        print(header)
        print(separator)
        print(f"{'åºå·':<5} {'é¡¶ç‚¹ç»„åç§°':<30} {'æ“ä½œçŠ¶æ€':<20}")
        print("-" * 55)
        
        # æ‰“å°æ’åºåçš„æœ€ç»ˆåˆ—è¡¨
        for i, (name, status) in enumerate(result['final_list']):
            print(f"{i+1:<5} {name:<30} {status:<20}")

        
        print(separator)
        print("æ€»ç»“:")
        print(f"  æºAç‰©ä½“é¡¶ç‚¹ç»„æ•°é‡: {result['source_total']}")
        print(f"  ç›®æ ‡Bç‰©ä½“åŸå§‹æ•°é‡: {result['original_total']}")
        print("-" * 15)
        print(f"  å·²åŒ¹é…å¹¶ç§»åŠ¨æ•°é‡: {result['matched']}")
        print(f"  æ–°å»ºç©ºç»„æ•°é‡: {result['added']}")
        print(f"  å¤šä½™å¹¶ä¿ç•™æ•°é‡: {result['extra']}")
        print(f"  æœ€ç»ˆé¡¶ç‚¹ç»„æ€»æ•°: {len(result['final_list'])}")
        print(separator)



def register():
    bpy.utils.register_class(DATA_PT_vertex_group_tools)
    bpy.utils.register_class(O_VertexGroupsCount)
    bpy.utils.register_class(O_VertexGroupsDelNoneActive)
    bpy.utils.register_class(O_VertexGroupsMatchRename)
    bpy.utils.register_class(O_VertexGroupsSortMatch)

    bpy.types.Scene.similarity_threshold = bpy.props.FloatProperty(
        name="é¡¶ç‚¹ç»„ç›¸ä¼¼åº¦é˜ˆå€¼",
        description="åŒ¹é…é¡¶ç‚¹ç»„æ—¶çš„æœ€å°ç›¸ä¼¼åº¦(0-1)",
        default=0.94,
        min=0.9,
        max=1.0,
        step=0.01,
        precision=3
    )

def unregister():
    bpy.utils.unregister_class(DATA_PT_vertex_group_tools)
    bpy.utils.unregister_class(O_VertexGroupsCount)
    bpy.utils.unregister_class(O_VertexGroupsDelNoneActive)
    bpy.utils.unregister_class(O_VertexGroupsMatchRename)
    bpy.utils.unregister_class(O_VertexGroupsSortMatch)

    del bpy.types.Scene.similarity_threshold
